{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: Classifying the Data\n",
        "format:\n",
        "  html:\n",
        "    code-fold: true\n",
        "    code-tools: true\n",
        "    df-print: paged\n",
        "---"
      ],
      "id": "89c59f94"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Loading the cleaned data sets. Change the file path to match the one that you need. \n",
        "    - selecting the necessary columns \n",
        "    - filtering out values that are null on dx_oth\n"
      ],
      "id": "c2523122"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: raw-data\n",
        "#| fig-cap: The raw data when loaded from the CSV file\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "filepath = \"/Users/clairelichty/summer2023/SwissTPH/AutomatedClassification/02_timci_day0_data.csv\"\n",
        "raw_df = pd.read_csv(filepath, low_memory=False)\n",
        "df = pd.DataFrame(raw_df, columns = [\"dx_oth\", \"child_id\"])\n",
        "data_to_be_sorted = df[(df.dx_oth.notnull())]\n",
        "data_to_be_sorted"
      ],
      "id": "raw-data",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Start by creating the data structure that is going to be used to sort the items in the dataset \n"
      ],
      "id": "0dbd20a2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "    df_with_buckets = pd.DataFrame(columns = [\"dx_oth\", \"child_id\", \"category_no\"])\n",
        "    df_with_buckets"
      ],
      "id": "575fea8b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. Iterate through the list, if there is nothing already in the dataframe, as there is the first time, add it to the dataframe. \n",
        "    - The Category No. being one here means that this represents the first category, in order for something else to \"qualify\" for that category, it has to hit certain criteria, which are laid out in the function under point number 4. \n"
      ],
      "id": "889b5c09"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "    for dx_oth, child_id in zip(data_to_be_sorted[\"dx_oth\"], data_to_be_sorted[\"child_id\"]):\n",
        "        if len(df_with_buckets) == 0: \n",
        "            df_with_buckets.loc[0] = [dx_oth, child_id, 1]\n",
        "        else: \n",
        "            patient_data = (dx_oth, child_id)\n",
        "    df_with_buckets"
      ],
      "id": "52d6a885",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4. Comparing to the criteria\n",
        "    - This function will take in the patient_data, as the tuple (dx_oth, child_id) and it will decide which bucket to place it in, or if to make a new bucket with it. \n",
        "        - The criteria to place a word in a bucket is that it has to pass at least 2 out of 3 thresholds: \n",
        "            - Lavenshtein Ratio, Jaro-Winkler Distance, and N-Gram Similarity\n",
        "        - After running the program on the data from the most recent (as of 06/07/23) TIMCI data from Kenya, the following data was produced: \n"
      ],
      "id": "4a3686ac"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import classificationEquations \n",
        "buckets = [1]\n",
        "for row in data_to_be_sorted.itertuples():\n",
        "    i = 0\n",
        "    cat_num = 0\n",
        "    for row_sorted in df_with_buckets.itertuples():\n",
        "        i+=1; \n",
        "        jaro = classificationEquations.compare_with_jar(row.dx_oth, row_sorted.dx_oth)\n",
        "        lev = classificationEquations.compare_with_lev(row.dx_oth, row_sorted.dx_oth)\n",
        "        ngram = classificationEquations.compare_with_ngram(row.dx_oth, row_sorted.dx_oth)         \n",
        "        \n",
        "        if((jaro and lev) or (jaro and ngram) or (lev and ngram)):\n",
        "            # means that this has \"passed\" the requirements to enter a bucket. \n",
        "            ## establishes that this is the category number that fits for this data. Have to check with the rest of the category. \n",
        "            cat_num = row_sorted.category_no \n",
        "            df_with_buckets.loc[len(df_with_buckets)] = [row.dx_oth, row.child_id, cat_num]\n",
        "            break \n",
        "        else:\n",
        "        #     ## they did not pass the test, should check if you're at the end of the list.\n",
        "            if( i == len(df_with_buckets)):\n",
        "        #         row_to_add = {\"dx_oth\": row.dx_oth, \"child_id\": row.child_id, \"category_no\": row_sorted.category_no + 1}\n",
        "                 cat_num = max(buckets) + 1\n",
        "                 buckets.append(cat_num)\n",
        "                 df_with_buckets.loc[len(df_with_buckets)] = [row.dx_oth, row.child_id, cat_num]\n",
        "                 break\n",
        "            \n",
        "df_with_buckets"
      ],
      "id": "75d494cb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On examining these categorizations, we can evaluate whether or not the current thresholds are effective for distingushing between words. Specifically considering how they compare to the IMCI and ICD-11 standards.  \n"
      ],
      "id": "e85289a4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import compareToStandards\n",
        "list_of_dfs = []\n",
        "dx_entry_per_category = {}\n",
        "for cat_no in buckets:\n",
        "    list_of_dfs.append(df_with_buckets[df_with_buckets[\"category_no\"] == cat_no])\n",
        "\n",
        "compareToStandards.readfile()\n",
        "\n",
        "for df in list_of_dfs:    \n",
        "    cat_no = df.iloc[0].category_no \n",
        "    num_entries = len(df)\n",
        "    dx_entry_per_category[cat_no] = num_entries\n",
        "    compareToStandards.compare_with_df(df)\n",
        "\n",
        "compareToStandards.get_sorting_count()\n"
      ],
      "id": "7cc60090",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}